{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Smart Claim BPJS - Fraud Detection Model Training\n",
                "\n",
                "Notebook ini digunakan untuk melatih model Random Forest untuk deteksi fraud pada klaim BPJS.\n",
                "\n",
                "## Tahapan:\n",
                "1. Generate dummy training data\n",
                "2. Data cleaning dan preprocessing\n",
                "3. Feature engineering\n",
                "4. Train/test split\n",
                "5. Model training (Random Forest)\n",
                "6. Evaluation\n",
                "7. Save model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "import pickle\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Add parent directory to path\n",
                "sys.path.append('..')\n",
                "from utils.data_generator import *\n",
                "\n",
                "print(\"✓ Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Generate Training Data\n",
                "\n",
                "Generate 1500 dummy samples:\n",
                "- 800 legitimate claims (label=0)\n",
                "- 700 fraudulent claims (label=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_training_sample(is_fraud=False):\n",
                "    \"\"\"\n",
                "    Generate a single training sample\n",
                "    \n",
                "    Args:\n",
                "        is_fraud: If True, generate fraudulent claim; else legitimate\n",
                "    \"\"\"\n",
                "    diagnosis = generate_diagnosis()\n",
                "    severity_map = {'mild': 1, 'moderate': 2, 'severe': 3}\n",
                "    diagnosis_severity = severity_map[diagnosis['severity']]\n",
                "    \n",
                "    if is_fraud:\n",
                "        # Fraudulent claim: inconsistencies\n",
                "        # 1. Mild diagnosis but severe vitals/labs\n",
                "        # 2. Severe diagnosis but normal vitals/labs\n",
                "        # 3. Inflated claim amount\n",
                "        \n",
                "        fraud_type = np.random.choice(['upcoding', 'phantom', 'inconsistent'])\n",
                "        \n",
                "        if fraud_type == 'upcoding':\n",
                "            # Mild diagnosis but high claim\n",
                "            diagnosis['severity'] = 'mild'\n",
                "            diagnosis_severity = 1\n",
                "            vital_signs = generate_vital_signs(False)  # Normal vitals\n",
                "            lab_results = generate_lab_results(False)  # Normal labs\n",
                "            claim_amount = generate_claim_amount('severe') * np.random.uniform(1.5, 3.0)\n",
                "        elif fraud_type == 'phantom':\n",
                "            # Severe diagnosis but normal findings\n",
                "            diagnosis['severity'] = 'severe'\n",
                "            diagnosis_severity = 3\n",
                "            vital_signs = generate_vital_signs(False)  # Normal vitals (suspicious!)\n",
                "            lab_results = generate_lab_results(False)  # Normal labs (suspicious!)\n",
                "            claim_amount = generate_claim_amount('severe')\n",
                "        else:\n",
                "            # Random inconsistencies\n",
                "            vital_signs = generate_vital_signs(np.random.choice([True, False]))\n",
                "            lab_results = generate_lab_results(np.random.choice([True, False]))\n",
                "            claim_amount = generate_claim_amount(diagnosis['severity']) * np.random.uniform(1.2, 2.5)\n",
                "    else:\n",
                "        # Legitimate claim: consistent data\n",
                "        abnormal = diagnosis['severity'] in ['moderate', 'severe']\n",
                "        vital_signs = generate_vital_signs(abnormal)\n",
                "        lab_results = generate_lab_results(diagnosis['severity'] == 'severe')\n",
                "        claim_amount = generate_claim_amount(diagnosis['severity']) * np.random.uniform(0.8, 1.2)\n",
                "    \n",
                "    # Create feature dict\n",
                "    features = {\n",
                "        'diagnosis_severity': diagnosis_severity,\n",
                "        'systolic_bp': vital_signs['systolic_bp'],\n",
                "        'diastolic_bp': vital_signs['diastolic_bp'],\n",
                "        'temperature': vital_signs['temperature'],\n",
                "        'pulse': vital_signs['pulse'],\n",
                "        'respiratory_rate': vital_signs['respiratory_rate'],\n",
                "        'hemoglobin': lab_results['hemoglobin'],\n",
                "        'leukocyte': lab_results['leukocyte'],\n",
                "        'platelet': lab_results['platelet'],\n",
                "        'hematocrit': lab_results['hematocrit'],\n",
                "        'claim_amount': int(claim_amount),\n",
                "        'is_fraud': 1 if is_fraud else 0\n",
                "    }\n",
                "    \n",
                "    return features\n",
                "\n",
                "# Generate dataset\n",
                "print(\"Generating training data...\")\n",
                "data = []\n",
                "\n",
                "# Generate legitimate claims\n",
                "for i in range(800):\n",
                "    data.append(generate_training_sample(is_fraud=False))\n",
                "\n",
                "# Generate fraudulent claims\n",
                "for i in range(700):\n",
                "    data.append(generate_training_sample(is_fraud=True))\n",
                "\n",
                "# Create DataFrame\n",
                "df = pd.DataFrame(data)\n",
                "\n",
                "print(f\"✓ Generated {len(df)} samples\")\n",
                "print(f\"  - Legitimate: {(df['is_fraud']==0).sum()}\")\n",
                "print(f\"  - Fraudulent: {(df['is_fraud']==1).sum()}\")\n",
                "print(f\"\\nDataset shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Exploration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic statistics\n",
                "print(\"Dataset Info:\")\n",
                "print(df.info())\n",
                "print(\"\\nBasic Statistics:\")\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values\n",
                "print(\"Missing values:\")\n",
                "print(df.isnull().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize fraud distribution\n",
                "plt.figure(figsize=(8, 5))\n",
                "df['is_fraud'].value_counts().plot(kind='bar')\n",
                "plt.title('Fraud Distribution')\n",
                "plt.xlabel('Is Fraud')\n",
                "plt.ylabel('Count')\n",
                "plt.xticks([0, 1], ['Legitimate', 'Fraudulent'], rotation=0)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create derived features\n",
                "df['bp_ratio'] = df['systolic_bp'] / df['diastolic_bp']\n",
                "df['fever'] = (df['temperature'] > 37.5).astype(int)\n",
                "df['tachycardia'] = (df['pulse'] > 100).astype(int)\n",
                "df['tachypnea'] = (df['respiratory_rate'] > 20).astype(int)\n",
                "df['anemia'] = (df['hemoglobin'] < 13.0).astype(int)\n",
                "df['leukopenia'] = (df['leukocyte'] < 4000).astype(int)\n",
                "df['thrombocytopenia'] = (df['platelet'] < 150000).astype(int)\n",
                "\n",
                "# Consistency checks\n",
                "df['amount_severity_mismatch'] = ((df['diagnosis_severity'] == 1) & (df['claim_amount'] > 2000000)).astype(int)\n",
                "df['vitals_severity_mismatch'] = ((df['diagnosis_severity'] == 3) & (df['fever'] == 0) & (df['tachycardia'] == 0)).astype(int)\n",
                "\n",
                "print(\"✓ Feature engineering completed\")\n",
                "print(f\"Total features: {df.shape[1] - 1}\")  # -1 for target variable\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation heatmap\n",
                "plt.figure(figsize=(14, 10))\n",
                "correlation = df.corr()\n",
                "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
                "plt.title('Feature Correlation Heatmap')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Show correlation with target\n",
                "print(\"\\nCorrelation with fraud label:\")\n",
                "print(correlation['is_fraud'].sort_values(ascending=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Preprocessing & Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separate features and target\n",
                "X = df.drop('is_fraud', axis=1)\n",
                "y = df['is_fraud']\n",
                "\n",
                "print(f\"Features shape: {X.shape}\")\n",
                "print(f\"Target shape: {y.shape}\")\n",
                "print(f\"\\nFeatures: {list(X.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/test split (80/20)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Training set: {X_train.shape[0]} samples\")\n",
                "print(f\"Test set: {X_test.shape[0]} samples\")\n",
                "print(f\"\\nTraining set fraud distribution:\")\n",
                "print(y_train.value_counts())\n",
                "print(f\"\\nTest set fraud distribution:\")\n",
                "print(y_test.value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scale numerical features\n",
                "scaler = StandardScaler()\n",
                "\n",
                "# Identify numerical columns to scale\n",
                "numerical_cols = [\n",
                "    'systolic_bp', 'diastolic_bp', 'temperature', 'pulse', 'respiratory_rate',\n",
                "    'hemoglobin', 'leukocyte', 'platelet', 'hematocrit', 'claim_amount', 'bp_ratio'\n",
                "]\n",
                "\n",
                "# Fit scaler on training data\n",
                "X_train_scaled = X_train.copy()\n",
                "X_test_scaled = X_test.copy()\n",
                "\n",
                "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
                "X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
                "\n",
                "print(\"✓ Feature scaling completed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Training - Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Random Forest Classifier\n",
                "rf_model = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=10,\n",
                "    min_samples_split=5,\n",
                "    min_samples_leaf=2,\n",
                "    random_state=42,\n",
                "    n_jobs=-1,\n",
                "    class_weight='balanced'  # Handle class imbalance\n",
                ")\n",
                "\n",
                "print(\"Training Random Forest model...\")\n",
                "rf_model.fit(X_train_scaled, y_train)\n",
                "print(\"✓ Model training completed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions\n",
                "y_train_pred = rf_model.predict(X_train_scaled)\n",
                "y_test_pred = rf_model.predict(X_test_scaled)\n",
                "\n",
                "y_train_proba = rf_model.predict_proba(X_train_scaled)[:, 1]\n",
                "y_test_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
                "\n",
                "# Training set performance\n",
                "print(\"=\"*60)\n",
                "print(\"TRAINING SET PERFORMANCE\")\n",
                "print(\"=\"*60)\n",
                "print(classification_report(y_train, y_train_pred, target_names=['Legitimate', 'Fraudulent']))\n",
                "print(f\"ROC-AUC Score: {roc_auc_score(y_train, y_train_proba):.4f}\")\n",
                "\n",
                "# Test set performance\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"TEST SET PERFORMANCE\")\n",
                "print(\"=\"*60)\n",
                "print(classification_report(y_test, y_test_pred, target_names=['Legitimate', 'Fraudulent']))\n",
                "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_test_proba):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Training set\n",
                "cm_train = confusion_matrix(y_train, y_train_pred)\n",
                "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
                "axes[0].set_title('Training Set Confusion Matrix')\n",
                "axes[0].set_xlabel('Predicted')\n",
                "axes[0].set_ylabel('Actual')\n",
                "axes[0].set_xticklabels(['Legitimate', 'Fraudulent'])\n",
                "axes[0].set_yticklabels(['Legitimate', 'Fraudulent'])\n",
                "\n",
                "# Test set\n",
                "cm_test = confusion_matrix(y_test, y_test_pred)\n",
                "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
                "axes[1].set_title('Test Set Confusion Matrix')\n",
                "axes[1].set_xlabel('Predicted')\n",
                "axes[1].set_ylabel('Actual')\n",
                "axes[1].set_xticklabels(['Legitimate', 'Fraudulent'])\n",
                "axes[1].set_yticklabels(['Legitimate', 'Fraudulent'])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curve\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
                "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
                "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
                "plt.xlim([0.0, 1.0])\n",
                "plt.ylim([0.0, 1.05])\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
                "plt.legend(loc=\"lower right\")\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance\n",
                "feature_importance = pd.DataFrame({\n",
                "    'feature': X.columns,\n",
                "    'importance': rf_model.feature_importances_\n",
                "}).sort_values('importance', ascending=False)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
                "plt.title('Feature Importance')\n",
                "plt.xlabel('Importance')\n",
                "plt.ylabel('Feature')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nTop 10 Most Important Features:\")\n",
                "print(feature_importance.head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create models directory if it doesn't exist\n",
                "os.makedirs('../models', exist_ok=True)\n",
                "\n",
                "# Save model\n",
                "model_path = '../models/fraud_detection_model.pkl'\n",
                "with open(model_path, 'wb') as f:\n",
                "    pickle.dump(rf_model, f)\n",
                "print(f\"✓ Model saved to {model_path}\")\n",
                "\n",
                "# Save scaler\n",
                "scaler_path = '../models/scaler.pkl'\n",
                "with open(scaler_path, 'wb') as f:\n",
                "    pickle.dump(scaler, f)\n",
                "print(f\"✓ Scaler saved to {scaler_path}\")\n",
                "\n",
                "# Save feature names for reference\n",
                "feature_names_path = '../models/feature_names.json'\n",
                "with open(feature_names_path, 'w') as f:\n",
                "    json.dump(list(X.columns), f)\n",
                "print(f\"✓ Feature names saved to {feature_names_path}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"MODEL TRAINING COMPLETED SUCCESSFULLY!\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Test Set Accuracy: {(y_test_pred == y_test).mean():.2%}\")\n",
                "print(f\"Test Set ROC-AUC: {roc_auc:.4f}\")\n",
                "print(\"\\nModel is ready for inference in the fraud detection pipeline.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}